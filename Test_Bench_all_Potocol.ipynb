{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test Bench all Potocol.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIeQbi6JGPPa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q4-_TTPyQje",
        "outputId": "195391cb-4496-4697-9f78-2d342f6f7ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ],
      "source": [
        "! pip install mtcnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8HDJT5jykLv",
        "outputId": "ae07d0d5-2407-415a-8f8f-fcbe1d8dd097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1GMQHnyYyncU"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm.notebook import tqdm as log_progress\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import data_utils\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "import os\n",
        "import pandas  as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "def model_photu(model,n=True,expand=False,direct='TB',shapes=True):\n",
        "   return plot_model(model, to_file='model_plot.png', show_shapes=shapes, show_layer_names=n,expand_nested=expand,rankdir=direct)\n",
        "#from keras.engine.topology import get_source_inputs\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "#from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "from tensorflow.python.keras.layers import Layer, InputSpec\n",
        "#from keras.applications.imagenet_utils import _obtain_input_shape\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.vis_utils import plot_model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +    'haarcascade_frontalface_default.xml')\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from keras.layers.merge import concatenate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "20wC9uNay3kZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l8UFyDgoy8YD"
      },
      "outputs": [],
      "source": [
        "def tf_loader(path,radi):\n",
        "    #img_org =image.load_img(path,target_size=(299,299,1),color_mode='grayscale')\n",
        "    #img_org=image.img_to_array(img_org)\n",
        "    #print('Enter full '+str(radi))\n",
        "    img_list=tf.unstack(path)\n",
        "    hists=[]\n",
        "    for img_org in img_list:\n",
        "     \n",
        "        img_org=img_org*255\n",
        "        #print('Squeese '+str(img_org.shape))\n",
        "        [Rows,Cols]=[img_org.shape[0],img_org.shape[1]]\n",
        "        if radi==53:\n",
        "            yTf  = tf_lbp_53_(img_org.reshape(1,Rows,Cols).astype('uint8')).numpy()\n",
        "        else:\n",
        "            yTf  = tf_lbp_35_(img_org.reshape(1,Rows,Cols).astype('uint8')).numpy()\n",
        "        \n",
        "        face_list.append(yTf)\n",
        "        face_titles.append('Full face')\n",
        "        hist,p= np.histogram(yTf.reshape(1,yTf.shape[1]*yTf.shape[2]),bins=range(0,256,31))\n",
        "        hists.append(tf.convert_to_tensor(hist,dtype='float32'))\n",
        "        \n",
        "    batched=tf.stack(hists)\n",
        "#    print(\"full \"+str(batched.shape))\n",
        "    return batched\n",
        "    \n",
        "\n",
        "# dividing full image into 4*4 region (level-2)\n",
        "\n",
        "def sliceBy16(path,radi):\n",
        "    #img_org =image.load_img(path,target_size=(299,299,1),color_mode='grayscale')\n",
        "    #img_org=image.img_to_array(img_org)\n",
        "    #print('Enter by 16 '+str(path.shape))\n",
        "    img_list=tf.unstack(path)\n",
        "    hists=[]\n",
        "    for img_org in img_list:\n",
        "        #img_org= tf.squeeze(path, axis=0)\n",
        "        #print('Squeese '+str(img_org.shape))\n",
        "        img_org=img_org*255\n",
        "        [H,w]=[img_org.shape[0],img_org.shape[1]]\n",
        "        \n",
        "        roi_00=img_org[           :int(H*0.25),           :int(w*0.25),:]\n",
        "        roi_10=img_org[           :int(H*0.25),int(w*.25 ):int(w*0.5 ),:]\n",
        "        roi_20=img_org[           :int(H*0.25),int(w*0.5 ):int(w*0.75),:]\n",
        "        roi_30=img_org[           :int(H*0.25),int(w*0.75):           ,:]\n",
        "        roi_01=img_org[int(H*0.25):int(H*0.5 ),           :int(w*0.25),:]\n",
        "        roi_11=img_org[int(H*0.25):int(H*0.5 ),int(w*.25 ):int(w*0.5 ),:]\n",
        "        roi_21=img_org[int(H*0.25):int(H*0.5 ),int(w*0.5 ):int(w*0.75),:]\n",
        "        roi_31=img_org[int(H*0.25):int(H*0.5 ),int(w*0.75):           ,:]\n",
        "        roi_02=img_org[int(H*0.5 ):int(H*0.75),           :int(w*0.25),:]\n",
        "        roi_12=img_org[int(H*0.5 ):int(H*0.75),int(w*.25 ):int(w*0.5 ),:]\n",
        "        roi_22=img_org[int(H*0.5 ):int(H*0.75),int(w*0.5 ):int(w*0.75),:]\n",
        "        roi_32=img_org[int(H*0.5 ):int(H*0.75),int(w*0.75):           ,:]\n",
        "        roi_03=img_org[int(H*0.75):      ,           :int(w*0.25)     ,:]\n",
        "        roi_13=img_org[int(H*0.75):      ,int(w*.25 ):int(w*0.5 )     ,:]\n",
        "        roi_23=img_org[int(H*0.75):      ,int(w*0.5 ):int(w*0.75)     ,:]\n",
        "        roi_33=img_org[int(H*0.75):      ,int(w*0.75):                ,:]\n",
        "    \n",
        "    \n",
        "    \n",
        "        if radi==53:\n",
        "            yTf_00  = tf_lbp_53_(roi_00.reshape(1,roi_00.shape[0],roi_00.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_10  = tf_lbp_53_(roi_10.reshape(1,roi_10.shape[0],roi_10.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_20  = tf_lbp_53_(roi_20.reshape(1,roi_20.shape[0],roi_20.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_30  = tf_lbp_53_(roi_30.reshape(1,roi_30.shape[0],roi_30.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_01  = tf_lbp_53_(roi_01.reshape(1,roi_01.shape[0],roi_01.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_11  = tf_lbp_53_(roi_11.reshape(1,roi_11.shape[0],roi_11.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_21  = tf_lbp_53_(roi_21.reshape(1,roi_21.shape[0],roi_21.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_31  = tf_lbp_53_(roi_31.reshape(1,roi_31.shape[0],roi_31.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_02  = tf_lbp_53_(roi_02.reshape(1,roi_02.shape[0],roi_02.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_12  = tf_lbp_53_(roi_12.reshape(1,roi_12.shape[0],roi_12.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_22  = tf_lbp_53_(roi_22.reshape(1,roi_22.shape[0],roi_22.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_32  = tf_lbp_53_(roi_32.reshape(1,roi_32.shape[0],roi_32.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_03  = tf_lbp_53_(roi_03.reshape(1,roi_03.shape[0],roi_03.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_13  = tf_lbp_53_(roi_13.reshape(1,roi_13.shape[0],roi_13.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_23  = tf_lbp_53_(roi_23.reshape(1,roi_23.shape[0],roi_23.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_33  = tf_lbp_53_(roi_33.reshape(1,roi_33.shape[0],roi_33.shape[1]).astype('uint8')).numpy()\n",
        "        else:\n",
        "            yTf_00  = tf_lbp_35_(roi_00.reshape(1,roi_00.shape[0],roi_00.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_10  = tf_lbp_35_(roi_10.reshape(1,roi_10.shape[0],roi_10.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_20  = tf_lbp_35_(roi_20.reshape(1,roi_20.shape[0],roi_20.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_30  = tf_lbp_35_(roi_30.reshape(1,roi_30.shape[0],roi_30.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_01  = tf_lbp_35_(roi_01.reshape(1,roi_01.shape[0],roi_01.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_11  = tf_lbp_35_(roi_11.reshape(1,roi_11.shape[0],roi_11.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_21  = tf_lbp_35_(roi_21.reshape(1,roi_21.shape[0],roi_21.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_31  = tf_lbp_35_(roi_31.reshape(1,roi_31.shape[0],roi_31.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_02  = tf_lbp_35_(roi_02.reshape(1,roi_02.shape[0],roi_02.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_12  = tf_lbp_35_(roi_12.reshape(1,roi_12.shape[0],roi_12.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_22  = tf_lbp_35_(roi_22.reshape(1,roi_22.shape[0],roi_22.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_32  = tf_lbp_35_(roi_32.reshape(1,roi_32.shape[0],roi_32.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_03  = tf_lbp_35_(roi_03.reshape(1,roi_03.shape[0],roi_03.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_13  = tf_lbp_35_(roi_13.reshape(1,roi_13.shape[0],roi_13.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_23  = tf_lbp_35_(roi_23.reshape(1,roi_23.shape[0],roi_23.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_33  = tf_lbp_35_(roi_33.reshape(1,roi_33.shape[0],roi_33.shape[1]).astype('uint8')).numpy()\n",
        "        \n",
        "        hs=[]\n",
        "        hist,p= np.histogram(yTf_00.reshape(1,yTf_00.shape[1]*yTf_00.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_10.reshape(1,yTf_10.shape[1]*yTf_10.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_20.reshape(1,yTf_20.shape[1]*yTf_20.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_30.reshape(1,yTf_30.shape[1]*yTf_30.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_01.reshape(1,yTf_01.shape[1]*yTf_01.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_11.reshape(1,yTf_11.shape[1]*yTf_11.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_21.reshape(1,yTf_21.shape[1]*yTf_21.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_31.reshape(1,yTf_31.shape[1]*yTf_31.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_02.reshape(1,yTf_02.shape[1]*yTf_02.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_12.reshape(1,yTf_12.shape[1]*yTf_12.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_22.reshape(1,yTf_22.shape[1]*yTf_22.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_32.reshape(1,yTf_32.shape[1]*yTf_32.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_03.reshape(1,yTf_03.shape[1]*yTf_03.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_13.reshape(1,yTf_13.shape[1]*yTf_13.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_23.reshape(1,yTf_23.shape[1]*yTf_23.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hist,p= np.histogram(yTf_33.reshape(1,yTf_33.shape[1]*yTf_33.shape[2]),bins=range(0,256,31));   hs=np.append(hs,hist)\n",
        "        hists.append(tf.convert_to_tensor(hs,dtype='float32'))\n",
        "        #print('hists');print(hists)\n",
        "        \n",
        "    batched=tf.stack(hists)\n",
        "#    print(\"16 \"+str(batched.shape))\n",
        "\n",
        "    return batched\n",
        "\n",
        "def sliceBy4(path,radi):\n",
        "    #img_org =image.load_img(path,target_size=(299,299,1),color_mode='grayscale')\n",
        "    #img_org=image.img_to_array(img_org)\n",
        "    #print('Enter by 4 '+str(radi))\n",
        "    img_list=tf.unstack(path)\n",
        "    hists=[]\n",
        "    for img_org in img_list:\n",
        "        img_org=img_org*255 \n",
        "        [H,w]=[img_org.shape[0],img_org.shape[1]]\n",
        "        \n",
        "        roi_00=img_org[:int(H*0.5),:int(w*0.5),:]\n",
        "        roi_01=img_org[int(H*0.5):,:int(w*0.5),:]\n",
        "        roi_10=img_org[:int(H*0.5),int(w*0.5):,:]\n",
        "        roi_11=img_org[int(H*0.5):,int(w*0.5):,:]\n",
        "        if radi==53:\n",
        "            yTf_00  = tf_lbp_53_(roi_00.reshape(1,roi_00.shape[0],roi_00.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_01  = tf_lbp_53_(roi_01.reshape(1,roi_01.shape[0],roi_01.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_10  = tf_lbp_53_(roi_10.reshape(1,roi_10.shape[0],roi_10.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_11  = tf_lbp_53_(roi_11.reshape(1,roi_11.shape[0],roi_11.shape[1]).astype('uint8')).numpy()\n",
        "        else:\n",
        "            yTf_00  = tf_lbp_35_(roi_00.reshape(1,roi_00.shape[0],roi_00.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_01  = tf_lbp_35_(roi_01.reshape(1,roi_01.shape[0],roi_01.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_10  = tf_lbp_35_(roi_10.reshape(1,roi_10.shape[0],roi_10.shape[1]).astype('uint8')).numpy()\n",
        "            yTf_11  = tf_lbp_35_(roi_11.reshape(1,roi_11.shape[0],roi_11.shape[1]).astype('uint8')).numpy()\n",
        "        hs=[]\n",
        "        hist,p= np.histogram(yTf_00.reshape(1,yTf_00.shape[1]*yTf_00.shape[2]),bins=range(0,256,31)) ;   hs=np.append(hs,hist)   \n",
        "        hist,p= np.histogram(yTf_01.reshape(1,yTf_01.shape[1]*yTf_01.shape[2]),bins=range(0,256,31)) ;   hs=np.append(hs,hist)   \n",
        "        hist,p= np.histogram(yTf_10.reshape(1,yTf_10.shape[1]*yTf_10.shape[2]),bins=range(0,256,31)) ;   hs=np.append(hs,hist)   \n",
        "        hist,p= np.histogram(yTf_11.reshape(1,yTf_11.shape[1]*yTf_11.shape[2]),bins=range(0,256,31)) ;   hs=np.append(hs,hist)\n",
        "        hists.append(tf.convert_to_tensor(hs,dtype='float32'))\n",
        "        #print('hists');print(hists)\n",
        "        \n",
        "    batched=tf.stack(hists)\n",
        " #   print(\"04 \"+str(batched.shape))\n",
        "\n",
        "    return batched    \n",
        "        \n",
        "\n",
        "# elbp for 5,3 --- general function for elbp--- calling function\n",
        "\n",
        "def tf_lbp_53_(img):    \n",
        "    \n",
        "    paddings = tf.constant([[0,0],[3, 3], [5, 5]])\n",
        "   # print('original shape '+str(img.shape))\n",
        "    img=tf.pad(img, paddings,\"CONSTANT\")        \n",
        "    b=img.shape \n",
        "    #print('padded shape '+str(img.shape))\n",
        "    \n",
        "  \n",
        "    Y=b[1]\n",
        "    X=b[2]\n",
        "    #print('Y= '+str(Y)+'  X ='+str(X))\n",
        "    img_padded=img\n",
        "    #select the pixels of masks in the form of matrices\n",
        "  \n",
        "    i00=img_padded[:,0:Y-6, 2:X-8] #T-left\n",
        "    i01=img_padded[:,0:Y-6, 5:X-5] #T-mid\n",
        "    i02=img_padded[:,0:Y-6, 8:X-2] #T-right     \n",
        "    i10=img_padded[:,3:Y-3, 0:X-10] #left\n",
        "    i11=img_padded[:,3:Y-3, 5:X-5]  # center /threshold\n",
        "    i12=img_padded[:,3:Y-3, 10:]    # right\n",
        "    i20=img_padded[:,6: , 2:X-8] #R-left\n",
        "    i21=img_padded[:,6: , 5:X-5] #R-mid\n",
        "    i22=img_padded[:,6: , 8:X-2] #R-right\n",
        "    g=tf.greater_equal(i01,i11)\n",
        "    z=   tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(1,dtype='uint8') )      \n",
        "    # 2 ---------------------------------\n",
        "    g=tf.greater_equal(i02,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(2,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)              \n",
        "    # 3 ---------------------------------\n",
        "    g=tf.greater_equal(i12,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(4,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)\n",
        "    # 4 ---------------------------------\n",
        "    g=tf.greater_equal(i22,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(8,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 5 ---------------------------------\n",
        "    g=tf.greater_equal(i21,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(16,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 6 ---------------------------------\n",
        "    g=tf.greater_equal(i20,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(32,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 7 ---------------------------------\n",
        "    g=tf.greater_equal(i10,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(64,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 8 ---------------------------------\n",
        "    g=tf.greater_equal(i00,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'), tf.constant(128,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    #---------------------------------    \n",
        "    return tf.cast(z,dtype=tf.uint8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# elbp for 3,5 --- general function for elbp--- calling function\n",
        "\n",
        "def tf_lbp_35_(img):    \n",
        "    \n",
        "    paddings = tf.constant([[0,0],[5,5], [3, 3]])\n",
        "    #print('original shape '+str(img.shape))\n",
        "    img=tf.pad(img, paddings,\"CONSTANT\")        \n",
        "    b=img.shape \n",
        "    #print('padded shape '+str(img.shape))\n",
        "    \n",
        "  \n",
        "    Y=b[1]\n",
        "    X=b[2]\n",
        "   # print('Y= '+str(Y)+'  X ='+str(X))\n",
        "    img_padded=img\n",
        "    #select the pixels of masks in the form of matrices\n",
        "  \n",
        "    i00=img_padded[:, 2:Y-8 ,0:X-6] #T-left\n",
        "    i01=img_padded[:, 5:Y-5 ,0:X-6] #T-mid\n",
        "    i02=img_padded[:, 8:Y-2 ,0:X-6] #T-right     \n",
        "    i10=img_padded[:, 0:Y-10,3:X-3] #left\n",
        "    i11=img_padded[:, 5:Y-5 ,3:X-3]  # center /threshold\n",
        "    i12=img_padded[:,10:    ,3:X-3]    # right\n",
        "    i20=img_padded[:, 2:Y-8 ,6:   ] #R-left\n",
        "    i21=img_padded[:, 5:Y-5 ,6:   ] #R-mid\n",
        "    i22=img_padded[:, 8:Y-2 ,6:   ] #R-right\n",
        "    g=tf.greater_equal(i01,i11)\n",
        "    z=   tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(1,dtype='uint8') )      \n",
        "    # 2 ---------------------------------\n",
        "    g=tf.greater_equal(i02,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(2,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)              \n",
        "    # 3 ---------------------------------\n",
        "    g=tf.greater_equal(i12,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(4,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)\n",
        "    # 4 ---------------------------------\n",
        "    g=tf.greater_equal(i22,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(8,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 5 ---------------------------------\n",
        "    g=tf.greater_equal(i21,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(16,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 6 ---------------------------------\n",
        "    g=tf.greater_equal(i20,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(32,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 7 ---------------------------------\n",
        "    g=tf.greater_equal(i10,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'),tf.constant(64,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    # 8 ---------------------------------\n",
        "    g=tf.greater_equal(i00,i11)\n",
        "    tmp= tf.multiply(tf.cast(g,dtype='uint8'), tf.constant(128,dtype='uint8') )\n",
        "    z =tf.add(z,tmp)  \n",
        "    #---------------------------------    \n",
        "    return tf.cast(z,dtype=tf.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mj-HapPkzC-f"
      },
      "outputs": [],
      "source": [
        "class ComputeLBP_full_53(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeLBP_full_53, self).__init__()\n",
        "        self.LBP_features = tf.Variable(initial_value=tf.zeros(8,dtype='uint8'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        \n",
        "        hist= tf.py_function( tf_loader, \n",
        "                           [inputs,53],\n",
        "                           'float32')\n",
        "        \n",
        "        self.LBP_features=tf.cast(tf.reshape(hist,[-1,8]), tf.float32)\n",
        "        return self.LBP_features\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "\n",
        "# Reference : https://www.tensorflow.org/api_docs/python/tf/image/rgb_to_hsv    \n",
        "class GrayMaker(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(GrayMaker, self).__init__()\n",
        "        self.Gray = tf.Variable(initial_value=tf.zeros([299,299,1],dtype='float32'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        \n",
        "        G= tf.image.rgb_to_grayscale(inputs)\n",
        "        self.Gray=G\n",
        "        \n",
        "        return self.Gray\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "class V_extractor(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(V_extractor, self).__init__()\n",
        "        self.V_channel = tf.Variable(initial_value=tf.zeros([299,299,1],dtype='float32'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):     \n",
        "      \n",
        "        G= tf.image.rgb_to_hsv(inputs)\n",
        "        v2=tf.expand_dims(G[:,:,:,2], 3)\n",
        "        self.V_channel=v2\n",
        "        return self.V_channel\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "        \n",
        "\n",
        "class ComputeLBP_4_53(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeLBP_4_53, self).__init__()\n",
        "        self.LBP_features = tf.Variable(initial_value=tf.zeros(32,dtype='uint8'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \n",
        "        hs= tf.py_function( sliceBy4, \n",
        "                           [inputs,53],\n",
        "                           'float32')   \n",
        "        \n",
        "        self.LBP_features=tf.cast(tf.reshape(hs,[-1,32]), tf.float32)\n",
        "        return self.LBP_features\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "class ComputeLBP_16_53(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeLBP_16_53, self).__init__()\n",
        "        self.LBP_features = tf.Variable(initial_value=tf.zeros(128,dtype='uint8'), trainable=False)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        hs= tf.py_function( sliceBy16, \n",
        "                           [inputs,53],\n",
        "                           'float32') \n",
        "        \n",
        "        self.LBP_features=tf.cast(tf.reshape(hs,[-1,128]), tf.float32)\n",
        "        return self.LBP_features\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "class ComputeLBP_full_35(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeLBP_full_35, self).__init__()\n",
        "        self.LBP_features = tf.Variable(initial_value=tf.zeros(8,dtype='uint8'), trainable=False)\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    def call(self, inputs):\n",
        "        #print(inputs)\n",
        "        hist= tf.py_function( tf_loader,[inputs,35],\n",
        "                           'float32')\n",
        "        \n",
        "        self.LBP_features=tf.cast(tf.reshape(hist,[-1,8]), tf.float32)\n",
        "        return self.LBP_features\n",
        "\n",
        "\n",
        "class ComputeLBP_4_35(keras.layers.Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeLBP_4_35, self).__init__()\n",
        "        self.LBP_features = tf.Variable(initial_value=tf.zeros(32,dtype='uint8'), trainable=False)\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        hs= tf.py_function( sliceBy4, \n",
        "                           [inputs,35],\n",
        "                           'float32') \n",
        "        \n",
        "        self.LBP_features=tf.cast(tf.reshape(hs,[-1,32]), tf.float32)\n",
        "\n",
        "        return self.LBP_features\n",
        "\n",
        "class ComputeLBP_16_35(keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, input_dim):\n",
        "        super(ComputeLBP_16_35, self).__init__()\n",
        "        self.LBP_features = tf.Variable(initial_value=tf.zeros(128,dtype='uint8'), trainable=False)\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        hs= tf.py_function( sliceBy16, \n",
        "                           [inputs,35],\n",
        "                           'float32') \n",
        "        self.LBP_features=tf.cast(tf.reshape(hs,[-1,128]), tf.float32)\n",
        "        return self.LBP_features\n",
        "    \n",
        "class FacePlate(keras.layers.Layer):\n",
        "    \n",
        "    def __init__(self, input_dim):\n",
        "        super(FacePlate, self).__init__()\n",
        "        self.Faces = tf.Variable(initial_value=tf.zeros(input_dim), trainable=False)\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        return config\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        #print('in Faceplae')\n",
        "        hs= tf.py_function( getFace,                            [inputs],                           'float32') \n",
        "        #print(inputs.shape)\n",
        "        #print('Faceplate'+str(hs.shape))\n",
        "        self.Faces=tf.cast(tf.reshape(hs,[-1,100,100,3]), tf.float32)\n",
        "        return self.Faces\n",
        "        \n",
        "\n",
        "def show_image_list(list_images, list_titles=None, list_cmaps=None, grid=True, num_cols=3, figsize=(20, 10), title_fontsize=10,show_titles=False):\n",
        "    num_images  = len(list_images)\n",
        "    num_rows    = int(num_images / num_cols) + (1 if num_images % num_cols != 0 else 0)\n",
        "\n",
        "    # Create a grid of subplots.\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
        "    \n",
        "    # Create list of axes for easy iteration.\n",
        "    if isinstance(axes, np.ndarray):\n",
        "        list_axes = list(axes.flat)\n",
        "    else:\n",
        "        list_axes = [axes]\n",
        "\n",
        "    for i in range(num_images):\n",
        "\n",
        "        img    = list_images[i]\n",
        "        title  = list_titles[i] if list_titles is not None else 'Image %d' % (i)\n",
        "        cmap   =  'gray'\n",
        "        \n",
        "        list_axes[i].imshow(img, cmap=cmap)\n",
        "        \n",
        "        \n",
        "        \n",
        "        if(show_titles):\n",
        "            list_axes[i].set_title(title, fontsize=title_fontsize) \n",
        "        #list_axes[i].grid(grid)\n",
        "\n",
        "    for i in range(num_images, len(list_axes)):\n",
        "        list_axes[i].set_visible(False)\n",
        "\n",
        "    plt.axis('off')\n",
        "\n",
        "    _ = plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Q8f8CEoTzFko"
      },
      "outputs": [],
      "source": [
        "\n",
        "g=[]\n",
        "debugs=[]\n",
        "def getFace(img):\n",
        "    global g\n",
        "    frames=[]\n",
        "    for frame in img:\n",
        "        debugs.append(str(frame.shape))\n",
        "        #print(frame.shape)\n",
        "        f=getFace1(frame)\n",
        "        frames.append(f)\n",
        "#        g.append(f)   \n",
        "    #print('batch done')  \n",
        "    f_s=tf.Variable(initial_value=tf.zeros((100,100,3),dtype= 'float32'), trainable=False)\n",
        "    i=0;\n",
        "    f_s=tf.stack(frames)\n",
        "    #print(f_s.shape)\n",
        "\n",
        "    return f_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lq22AII-zIhO"
      },
      "outputs": [],
      "source": [
        "face_list=[]\n",
        "face_titles=[]\n",
        "def getFace1(im):\n",
        "        global face_list\n",
        "        #face_list.append(face_cropped)\n",
        "        gray =float_to_Img(im.numpy())\n",
        "        gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        faces = face_cascade.detectMultiScale(gray,\n",
        "            scaleFactor=1.3,\n",
        "            minNeighbors=3,\n",
        "            minSize=(30, 30)\n",
        "        ) \n",
        "        try:\n",
        "            if len(faces) == 0:\n",
        "                    return im[0:100,0:100,:]\n",
        "                    print('no face')\n",
        "                    faces = detector.detect_faces(im.numpy())\n",
        "                    if len(faces) == 0:\n",
        "                                #face_list.append(im[0:100,0:100,:])\n",
        "                                #face_titles.append('mtcnn empty')\n",
        "                                return im[0:100,0:100,:]\n",
        "                    x, y, w, h = faces[0]['box']\n",
        "                    face_cropped=im[y-10:y+h+10,x-10:x+w+10,:]\n",
        "                    \n",
        "                    rescaled=cv2.resize((face_cropped.numpy()), [100,100], interpolation=cv2.INTER_AREA)\n",
        "                    #face_list.append(rescaled)\n",
        "                    #face_titles.append('mtcnn')               \n",
        "                    return face_cropped\n",
        "                    \n",
        "                    \n",
        "            #print(str(len(faces))+'  '+str(faces[0]))\n",
        "            [x,y,w,h]=faces[0]\n",
        "            face_cropped=im[y-10:y+h+10,x-10:x+w+10,:]\n",
        "            rescaled=cv2.resize((face_cropped.numpy()), [100,100], interpolation=cv2.INTER_AREA)\n",
        "            \n",
        "            #face_list.append(rescaled)\n",
        "            #face_titles.append('cropped face')\n",
        "            \n",
        "                \n",
        "            return rescaled\n",
        "        except :\n",
        "            return im[0:100,0:100,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gs3KrEaDzNnA"
      },
      "outputs": [],
      "source": [
        "def float_to_Img(ar):\n",
        "    \n",
        "    shape=ar.shape\n",
        "    img = np.zeros([ar.shape[0],ar.shape[0],3],dtype='uint8')\n",
        "\n",
        "    img[:,:,0] = ar[:,:,0]*255\n",
        "    img[:,:,1] = ar[:,:,1]*255\n",
        "    img[:,:,2] = ar[:,:,2]*255\n",
        "    #plt.imshow(img)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rpqq7Vs1zQQ2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def SqueezeAndExcitation(z,name1):\n",
        "    b,h,w,c = z.shape\n",
        "    ratio=16\n",
        "    #squeeze\n",
        "    y = keras.layers.GlobalAveragePooling2D(name=name1+'glob')(z) \n",
        "    #Excitation operation\n",
        "    y= Dense(c//ratio, activation='relu',name=name1+'relu', use_bias= False)(y)\n",
        "    y = keras.layers.Dense(c, activation='sigmoid', use_bias=False,name=name1+'sig')(y)\n",
        "    y = keras.layers.multiply([z,y],name=name1)\n",
        "    #y.name=name1\n",
        "    return y  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ypqA4qeqonHx"
      },
      "outputs": [],
      "source": [
        "from keras.layers.merge import concatenate\n",
        "def Full_Model(include_top=False, weights='imagenet', input_shape=(299,299,3),input_tensor=None):\n",
        "    \n",
        "    if input_tensor is None:\n",
        "        img_input = layers.Input(shape=input_shape)\n",
        "    else:\n",
        "       if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "       else:\n",
        "          img_input = input_tensor\n",
        "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name='block1_conv1')(img_input)\n",
        "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
        "    x = Activation('relu', name='block1_conv1_act')(x)\n",
        "    x = Conv2D(64, (3, 3), use_bias=False, name='block1_conv2')(x)\n",
        "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
        "    x = Activation('relu', name='block1_conv2_act')(x)\n",
        "\n",
        "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block2_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False, name='block2_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block2_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
        "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False, name='block3_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block3_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    residual = Conv2D(728, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = Activation('relu', name='block4_sepconv1_act')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block4_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block4_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block4_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block4_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block4_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "    # entry flow features to squeeze excitation block\n",
        "    s=x\n",
        "    # entry flow complete\n",
        "    # middle flow starts\n",
        "\n",
        "    for i in range(8):\n",
        "        residual = x\n",
        "        prefix = 'block' + str(i + 5)\n",
        "\n",
        "        x = Activation('relu', name=prefix + '_sepconv1_act')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv1')(x)\n",
        "        x = BatchNormalization(name=prefix + '_sepconv1_bn')(x)\n",
        "        x = Activation('relu', name=prefix + '_sepconv2_act')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv2')(x)\n",
        "        x = BatchNormalization(name=prefix + '_sepconv2_bn')(x)\n",
        "        x = Activation('relu', name=prefix + '_sepconv3_act')(x)\n",
        "        x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name=prefix + '_sepconv3')(x)\n",
        "        x = BatchNormalization(name=prefix + '_sepconv3_bn')(x)\n",
        "        \n",
        "       \n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "    f=x\n",
        "    # middle flow endend---- add squeeze excitation block\n",
        "        # exit flow starting\n",
        "    residual = Conv2D(1024, (1, 1), strides=(2, 2),\n",
        "                      padding='same', use_bias=False)(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "\n",
        "    x = Activation('relu', name='block13_sepconv1_act')(x)\n",
        "    x = SeparableConv2D(728, (3, 3), padding='same', use_bias=False, name='block13_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block13_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block13_sepconv2_act')(x)\n",
        "    x = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False, name='block13_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block13_sepconv2_bn')(x)\n",
        "\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='block13_pool')(x)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "    x = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False, name='block14_sepconv1')(x)\n",
        "    x = BatchNormalization(name='block14_sepconv1_bn')(x)\n",
        "    x = Activation('relu', name='block14_sepconv1_act')(x)\n",
        "\n",
        "    x = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False, name='block14_sepconv2')(x)\n",
        "    x = BatchNormalization(name='block14_sepconv2_bn')(x)\n",
        "    x = Activation('relu', name='block14_sepconv2_act')(x)\n",
        "    \n",
        "\n",
        "    if include_top:\n",
        "          x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "          outputs = Dense(2, activation='softmax', name='predictions')(x)\n",
        "    else:\n",
        "         y=SqueezeAndExcitation(s,'Se1') #squeeze excitation to entry block\n",
        "         z=SqueezeAndExcitation(f,'Se2') #squeeze excitation to middle flow\n",
        "         q=SqueezeAndExcitation(x,'Se3')\n",
        "         a= keras.layers.Flatten()(q)\n",
        "         d=layers.add([y,z])\n",
        "         e= keras.layers.Flatten()(d)\n",
        "         g=keras.layers.concatenate([a,e])\n",
        "         p=keras.layers.Dense(512, activation='relu')(g)\n",
        "         p=keras.layers.Dense(16,activation='relu')(p)\n",
        "         outputs = keras.layers.Dense(2,activation='softmax')(p)\n",
        "\n",
        "           #applying squeeze excitation at the ending block of exit\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    \n",
        "    # Create model.\n",
        "    model = Model(inputs, outputs, name='xception')\n",
        "    if ( weights=='Casia' ) :\n",
        "        model.load_weights('/content/drive/MyDrive/ML_Data/SE_Casia_Concat_weights.h5',by_name = True, skip_mismatch = True)\n",
        "    else:\n",
        "        model.load_weights('/content/drive/MyDrive/ML_Data/SE_Replay_Concat_weights.h5',by_name = True, skip_mismatch = True)\n",
        "\n",
        "    inputs_s = keras.Input(shape=(299, 299, 3))\n",
        "    inputs_s2 = keras.Input(shape=(299, 299, 3))\n",
        "    for l in model.layers:\n",
        "      l.trainable=False\n",
        "    X_model= Model(inputs=model.input, outputs=model.layers[-3].output,name='Squeeze_Xception')\n",
        "    faceGetter=FacePlate(input_dim=(299,299,1))(inputs_s2)\n",
        "    iLBp=keras.Input(shape=(faceGetter.shape[1],faceGetter.shape[2],faceGetter.shape[3]))\n",
        "    gray=GrayMaker(input_dim=iLBp.shape)(iLBp)\n",
        "    ELBP_Full_H=ComputeLBP_full_53(input_dim=gray.shape)(gray)\n",
        "    ELBP_Full_V=ComputeLBP_full_35(input_dim=gray.shape)(gray)\n",
        "    ELBP_by04_H=ComputeLBP_4_53   (input_dim=gray.shape)(gray)\n",
        "    ELBP_by04_V=ComputeLBP_4_35   (input_dim=gray.shape)(gray)\n",
        "    ELBP_by16_H=ComputeLBP_16_53  (input_dim=gray.shape)(gray)\n",
        "    ELBP_by16_V=ComputeLBP_16_35  (input_dim=gray.shape)(gray)\n",
        "    ELBP_full  =keras.layers.add([ELBP_Full_H,ELBP_Full_V],name='add_ELBP_full')\n",
        "    ELBP_by04  =keras.layers.add([ELBP_by04_H,ELBP_by04_V],name='add_ELBP_L1')\n",
        "    ELBP_by16  =keras.layers.add([ELBP_by16_H,ELBP_by16_V],name='add_ELBP_L2')\n",
        "    ELBP_Concated= keras.layers.concatenate([ELBP_full,ELBP_by04],name='all_lbp_concaterd')\n",
        "    LBP_container=keras.Model(iLBp,ELBP_Concated,name='ELBP')\n",
        "    \n",
        "    V_Chan=V_extractor(input_dim=iLBp.shape)(iLBp)\n",
        "    V_Chan_ELBP_Full_H = ComputeLBP_full_53(input_dim=V_Chan.shape)(V_Chan)\n",
        "    V_Chan_ELBP_Full_V = ComputeLBP_full_35(input_dim=V_Chan.shape)(V_Chan)\n",
        "    V_Chan_ELBP_by04_H = ComputeLBP_4_53   (input_dim=V_Chan.shape)(V_Chan)\n",
        "    V_Chan_ELBP_by04_V = ComputeLBP_4_35   (input_dim=V_Chan.shape)(V_Chan)\n",
        "    V_Chan_ELBP_by16_H = ComputeLBP_16_53  (input_dim=V_Chan.shape)(V_Chan)\n",
        "    V_Chan_ELBP_by16_V = ComputeLBP_16_35  (input_dim=V_Chan.shape)(V_Chan)\n",
        "    V_Chan_ELBP_full   = keras.layers.add([V_Chan_ELBP_Full_H,V_Chan_ELBP_Full_V],name='add_V_Chan_ELBP_full')\n",
        "    V_Chan_ELBP_by04   = keras.layers.add([V_Chan_ELBP_by04_H,V_Chan_ELBP_by04_V],name='add_V_Chan_ELBP_L1')\n",
        "    V_Chan_ELBP_by16   = keras.layers.add([V_Chan_ELBP_by16_H,V_Chan_ELBP_by16_V],name='add_V_Chan_ELBP_L2')\n",
        "    V_Chan_ELBP_Concated= keras.layers.concatenate([V_Chan_ELBP_full,V_Chan_ELBP_by04],name='all_V_Concat')\n",
        "    V_Chan_LBP_container=keras.Model(iLBp,V_Chan_ELBP_Concated,name='V_Channel_ELBP')\n",
        "\n",
        "\n",
        "    x_out=X_model(inputs_s2,training=False)\n",
        "    ELB_out=LBP_container(faceGetter)\n",
        "    V_ELB_out=V_Chan_LBP_container(faceGetter)\n",
        "    el_c=keras.layers.concatenate([ELB_out,V_ELB_out],axis=1,name='lbp_concat')\n",
        "    t=tf.keras.layers.Reshape((10, 8), name='lstm_')(el_c)\n",
        "    q=keras.layers.LSTM(64,return_sequences=True)(t)\n",
        "    q=keras.layers.LSTM(32)(q)\n",
        "    concat_all=keras.layers.concatenate([x_out,q],axis=1,name='lbp_concaterd')\n",
        "    p=keras.layers.Dense(256, activation='relu',name='e_dense_1')(concat_all)\n",
        "    p=keras.layers.Dense(64,activation='relu',name='e_dense_2')(p)\n",
        "    outputs = keras.layers.Dense(2,activation='sigmoid',name='e_dense_3')(p)\n",
        "    f_model=keras.Model(inputs_s2,outputs)    \n",
        "    f_model.compile(optimizer='adam', loss='binary_crossentropy',metrics=\"categorical_accuracy\",steps_per_execution=4)\n",
        "\n",
        "    return f_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights(model_path,isCasia=False):\n",
        "  if isCasia:\n",
        "    p_model=Full_Model(weights='Casia')\n",
        "  else : \n",
        "    p_model=Full_Model()\n",
        "  t_model=keras.models.load_model(model_path,custom_objects={\"getFace1\"   :getFace1,\n",
        "  \"getFace\"    :getFace,\n",
        "  \"tf_lbp_35_\" :tf_lbp_35_,\n",
        "  \"tf_lbp_53_\" :tf_lbp_53_,\n",
        "  \"sliceBy4\"   :sliceBy4,\n",
        "  \"tf_loader\"  :tf_loader})\n",
        "  i=0\n",
        "  for layer in t_model.layers:\n",
        "    print(layer.name, len(layer.get_weights ()))    \n",
        "    try:\n",
        "      p_model.layers[i].set_weights(layer.get_weights())\n",
        "    except:\n",
        "      print(\"err\",layer.name)\n",
        "    i=i+1\n",
        "    \n",
        "  return p_model  "
      ],
      "metadata": {
        "id": "-8wpXoDiININ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model Paths\n",
        "Casia ='/content/drive/MyDrive/ML_Data/SavedModels/Casia512_16_97'\n",
        "Replay='/content/drive/MyDrive/ML_Data/SavedModels/Replay512_16_97'\n",
        "OuluP1='/content/drive/MyDrive/ML_Data/SavedModels/OULU_P1_512_16'\n",
        "OuluP2='/content/drive/MyDrive/ML_Data/SavedModels/OULU_P2_512_16_a'\n",
        "OuluP3='/content/drive/MyDrive/ML_Data/SavedModels/OULU_P2_512_16_a'\n",
        "OuluP4='/content/drive/MyDrive/ML_Data/SavedModels/OULU_P2_512_16_a'\n",
        "\n",
        "#trained_model=load_weights(Replay)"
      ],
      "metadata": {
        "id": "98vUEKBJInkc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#test_folder ='/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/replay_data_every_10th/test'\n",
        "test_folder='/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/OULU_frames/Test_Files_frames'\n",
        "test_full = pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/OULU_Test_Labels_P1.csv')\n",
        "#test_full = pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/OULU_Test_Labels_P2.csv')\n",
        "#test_full = pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/OULU_Test_Labels_P3.csv')\n",
        "#test_full = pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/OULU_Test_Labels_P4.csv')\n",
        "#test_demo=test_full[::10]\n",
        "testData = test_gen.flow_from_dataframe(dataframe =test_demo,directory = test_folder,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFJ__-WMLMeV",
        "outputId": "77645812-a4fb-4207-dd59-b5e5f54ae2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 888 validated image filenames belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 792 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen= ImageDataGenerator(\n",
        "rescale=1./255\n",
        ")\n",
        "test_folder='/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/OULU_frames/Test_Files_frames_299'\n",
        "\n",
        "test_set = test_gen.flow_from_directory(test_folder,\n",
        "                                            target_size = (299, 299),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary',\n",
        "                                            shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjM-tCZmM7FY",
        "outputId": "323a9a76-31b0-41db-d8b4-de3b93e7057b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 49926 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD Model\n",
        "trained_model=load_weights(Replay)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZKonq7DL9J4",
        "outputId": "0d75a009-80cd-4ee8-f667-9d484bb3f674"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_3 0\n",
            "face_plate 1\n",
            "err face_plate\n",
            "ELBP 5\n",
            "err ELBP\n",
            "V_Channel_ELBP 5\n",
            "err V_Channel_ELBP\n",
            "lbp_concat 0\n",
            "lstm_ 0\n",
            "lstm 3\n",
            "Squeeze_Xception 242\n",
            "lstm_1 3\n",
            "lbp_concaterd 0\n",
            "e_dense_1 2\n",
            "e_dense_2 2\n",
            "e_dense_3 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replay on P1\n",
        "preds=trained_model.predict(test_set,  verbose = 1, use_multiprocessing = True, workers = 8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soDa4YUHL1Z0",
        "outputId": "47f9f37c-2c54-4514-a327-c8a8e76beb81"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1561/1561 [==============================] - 5199s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p=test_set.filenames\n",
        "DF = pd.DataFrame(preds)\n",
        "  \n",
        "# save the dataframe as a csv file\n"
      ],
      "metadata": {
        "id": "XN7W7KnipGWs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF['filenames']=p"
      ],
      "metadata": {
        "id": "gjiFZPWoOPkj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DF.to_csv(\"Replay_L01_inter_OULU_P1_result.csv\")"
      ],
      "metadata": {
        "id": "hU0BnopsOUYF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Val Datas\n",
        "\n",
        "import os\n",
        "train_F_Replay = '/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/replay_data_every_10th/train'\n",
        "val_F_Replay = '/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/replay_data_every_10th/dev'\n",
        "\n",
        "train_F_Casia = '/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/casia-fasd-rgb/db_train'\n",
        "val_F_Casia = '/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/casia-fasd-rgb/db_test'\n",
        "\n",
        "train_f_oulu = '/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/OULU_frames/Train_Files'\n",
        "val_f_oulu = '/content/drive/MyDrive/ML_Data/Datasets_Preprocessed/OULU_frames/Dev_Files_frames'\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define your data generator\n",
        "train_gen = ImageDataGenerator(\n",
        "rescale=1./255,\n",
        "horizontal_flip=True\n",
        ")\n",
        "val_gen = ImageDataGenerator(\n",
        "rescale=1./255,\n",
        "horizontal_flip=True\n",
        ")\n",
        "\n",
        "t1 = pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/Replay_train_rgb.csv')\n",
        "\n",
        "\n",
        "train_1_replay=t1.iloc[::2]\n",
        "train_2_replay=t1.iloc[1::2]\n",
        "\n",
        "dev_full = pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/Replay_dev_rgb.csv')\n",
        "dev_1_replay=dev_full.iloc[::4]\n",
        "dev_2_replay=dev_full.iloc[1::4]\n",
        "\n",
        "#Replay_train_Set_1 = train_gen.flow_from_dataframe(dataframe = train_1,directory = train_folder,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "#Replay_train_Set_2 = train_gen.flow_from_dataframe(dataframe = train_2,directory = train_folder,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "\n",
        "train_casia=pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/casia_train.csv')\n",
        "dev_casia=pd.read_csv('/content/drive/MyDrive/ML_Data/Labels/casia_test.csv')\n",
        "dev_casia=dev_casia[::3]\n",
        "Casia_train_Set = train_gen.flow_from_dataframe(dataframe = train_casia,directory = train_F_Casia,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "\n",
        "casia_val_set = val_gen.flow_from_dataframe(dataframe = dev_casia, directory = val_F_Casia, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szAGA8RAUbX-",
        "outputId": "ece01fa5-cac7-4027-eb85-370a4c04f773"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8729 validated image filenames belonging to 2 classes.\n",
            "Found 1295 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Oulu train sets\n",
        "Oulu_P1_train_Set_1 = train_gen.flow_from_dataframe(dataframe = train_1_oulu1,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P1_train_Set_2 = train_gen.flow_from_dataframe(dataframe = train_2_oulu1,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P2_train_Set_1 = train_gen.flow_from_dataframe(dataframe = train_1_oulu2,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P2_train_Set_2 = train_gen.flow_from_dataframe(dataframe = train_2_oulu2,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P3_train_Set_1 = train_gen.flow_from_dataframe(dataframe = train_1_oulu3,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P3_train_Set_2 = train_gen.flow_from_dataframe(dataframe = train_2_oulu3,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P4_train_Set_1 = train_gen.flow_from_dataframe(dataframe = train_1_oulu4,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "Oulu_P4_train_Set_2 = train_gen.flow_from_dataframe(dataframe = train_2_oulu4,directory = train_folder_oulu,  x_col = \"filename\", y_col = \"label\",batch_size =16, shuffle = True, class_mode='categorical',target_size = (299,299))\n",
        "\n",
        "\n",
        "Oulu_P1_val_data_1 = val_gen.flow_from_dataframe(dataframe = dev_1, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P1_val_data_2 = val_gen.flow_from_dataframe(dataframe = dev_2, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P2_val_data_1 = val_gen.flow_from_dataframe(dataframe = dev_1, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P2_val_data_2 = val_gen.flow_from_dataframe(dataframe = dev_2, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P3_val_data_1 = val_gen.flow_from_dataframe(dataframe = dev_1, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P3_val_data_2 = val_gen.flow_from_dataframe(dataframe = dev_2, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P4_val_data_1 = val_gen.flow_from_dataframe(dataframe = dev_1, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "Oulu_P4_val_data_2 = val_gen.flow_from_dataframe(dataframe = dev_2, directory = val_folder_oulu, x_col = 'filename', y_col = 'label',batch_size = 32, shuffle = False, class_mode= 'categorical',target_size = (299,299))\n",
        "\n"
      ],
      "metadata": {
        "id": "gFNMH4ExWRAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence  Replay - Casia - Oulu P1\n",
        "# Load Replay Model\n",
        "#trained_model=load_weights(Replay)\n",
        "\n",
        "# Train on Casia\n",
        "trained_model.fit(Casia_train_Set,epochs=2, validation_data=casia_val_set, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZb3oAT2qvsR",
        "outputId": "b10c263a-7716-473e-cd9e-95a7bcc428b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "128/546 [======>.......................] - ETA: 13:21 - loss: 0.7017 - categorical_accuracy: 0.7962"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train on Oulu\n",
        "\n",
        "trained_model.fit(Oulu_P1_train_Set_1,epochs=1, validation_data=Oulu_P1_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1')\n",
        "\n",
        "trained_model.fit(Oulu_P1_train_Set_2,epochs=1, validation_data=Oulu_P1_val_data_2, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1')\n",
        "\n",
        "\n",
        "trained_model.fit(Oulu_P2_train_Set_1,epochs=1, validation_data=Oulu_P2_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1_P2')\n",
        "\n",
        "trained_model.fit(Oulu_P2_train_Set_2,epochs=1, validation_data=Oulu_P2_val_data_2, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1_P2')\n",
        "\n",
        "trained_model.fit(Oulu_P3_train_Set_1,epochs=1, validation_data=Oulu_P3_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1_P2_P3')\n",
        "trained_model.fit(Oulu_P3_train_Set_2,epochs=1, validation_data=Oulu_P3_val_data_2, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1_P2_P3')\n",
        "\n",
        "trained_model.fit(Oulu_P4_train_Set_1,epochs=1, validation_data=Oulu_P4_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1_P2_P3_P4')\n",
        "trained_model.fit(Oulu_P4_train_Set_2,epochs=1, validation_data=Oulu_P4_val_data_2, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-OuluP1_P2_P3_P4')\n"
      ],
      "metadata": {
        "id": "6If5pco4OdTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence  Replay - Casia - MSU\n",
        "# Load Replay- Casia Model\n",
        "trained_model=load_weights('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia')\n",
        "\n",
        "\n",
        "# Train on MSU\n",
        "\n",
        "trained_model.fit(MSU_train_Set_1,epochs=1, validation_data=MSU_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-MSU')\n",
        "\n",
        "trained_model.fit(MSU_train_Set_1,epochs=1, validation_data=MSU_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-MSU')\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5ElY6BMXv1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence  Replay - OULu - MSU\n",
        "# Load Replay Model\n",
        "trained_model=load_weights('/content/drive/MyDrive/ML_Data/SavedModels/Replay')\n",
        "\n",
        "#\n",
        "trained_model.fit(Oulu_P1_train_Set_1,epochs=1, validation_data=Oulu_P1_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-OuluP1')\n",
        "\n",
        "trained_model.fit(Oulu_P1_train_Set_2,epochs=1, validation_data=Oulu_P1_val_data_2, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-OuluP1')\n",
        "\n",
        "# Train on MSU\n",
        "\n",
        "trained_model.fit(MSU_train_Set_1,epochs=1, validation_data=MSU_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-MSU')\n",
        "\n",
        "trained_model.fit(MSU_train_Set_1,epochs=1, validation_data=MSU_val_data_1, verbose = 1,use_multiprocessing = True, workers = 8)\n",
        "trained_model.save('/content/drive/MyDrive/ML_Data/SavedModels/Replay-Casia-MSU')\n"
      ],
      "metadata": {
        "id": "upDYZVMmYl_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}